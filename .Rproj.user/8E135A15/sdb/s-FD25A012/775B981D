{
    "contents" : "# Source file for utility and helper functions I've created over the years.\n# Adam Duncan, 2015\n\n# dMisc\n\nsuppressMessages(library(xts))\nsuppressMessages(library(xtsExtra))\nsuppressMessages(library(PerformanceAnalytics))\nsuppressMessages(library(ggplot2))\nsuppressMessages(library(gridExtra))\nsuppressMessages(library(factorAnalytics))\nsuppressMessages(library(caret))\n\nmakeXTS <- function(x, format = \"%Y-%m-%d\", names = colnames(x)[2:ncol(x)]){\n  ## Takes a data frame from read.csv, extracts the date column, and converts\n  ## the data frame to an xts object. First column of object should be \"Date\" and\n  ## contain the dates.\n  #   if(colnames(x)[1]!=\"Date\" || colnames(x)[1]!=\"Index\"){\n  #     return(\"First column must be labled 'Date' or 'Index' and should contain the dates.\")\n  #   }\n  dts <- as.Date(x[,1],format=format)\n  data <- x[,2:ncol(x)] # remove the date column\n  out <- xts(data,dts) # form the xts object\n  names(out) <- names\n  return(out)\n}\nxtsApply <- function(x, cFUN, margin = 2, ...) {\n  # an implementation of apply that works for xts objects...\n  if(!is.xts(x)) stop(\"Must supply function with xts object\")\n  \n  if(margin == 2){ # column-wise calculation\n    Z <- x\n    for (j in 1:ncol(x)) {\n      Z[,j] <- do.call(cFUN, list(x[,j],...))\n    }\n  } else { # row-wise calculation\n    Z <- xts(rep(0,nrow(x)),index(x))\n    for (j in 1:nrow(x)) {\n      Z[j,1] <- do.call(cFUN, list(x[j,],...))\n    }\n  }\n  return(Z)\n}\nxtsToDataFrame<-function(xts.obj){\n  # A function to convert an xts object into a data frame that can be plotted\n  # using ggplot2. The date column will be the first column of the new data\n  # frame and will have the name 'Date'. \n  # This function uses a recursive implementation for xts objects with many columns.\n  \n  if (ncol(xts.obj)==1) {\n    series.name <- colnames(xts.obj)[1]\n    tmp<-xts.obj\n    tmp.df <- as.data.frame(coredata(tmp))\n    tmp.df$Date <- as.POSIXct(index(tmp))\n    tmp.df.long <- melt(tmp.df,id.var=\"Date\")\n    tmp.df.long$asset <- rep(series.name,nrow(tmp.df.long))\n    return(tmp.df.long)\n  } else {\n    num.assets <- ncol(xts.obj)\n    asset.names <- colnames(xts.obj)\n    df <- do.call(rbind,lapply(1:num.assets,function(x){  \n      xtsToDataFrame(as.xts(xts.obj[,x]))\n    }))\n    df$asset <- ordered(df$asset, levels=asset.names)\n    return(df)\n  }\n}\nxtsAlign<-function(target, match.to, join=\"inner\"){\n  # Takes two xts objects and aligns their dates returning target with the same\n  # date structure as match.to (trims does not merge objects)\n  \n  dummy<-xts(rep(1,nrow(match.to)),index(match.to))\n  ret<-merge.xts(target,dummy,join=join)\n  ret<-subset(ret,select=(-dummy))\n  rm(dummy)\n  return(ret)\n}\nxtsMultiMerge <- function(xtslst, join=\"inner\"){\n  # A hack to allow merging multiple xts objects AND apply the\n  # desired database join. Default is \"inner\" join.\n  out <- NULL\n  for (i in 1:length(xtslst)){\n    out <- merge.xts(out,xtslst[[i]],join=\"inner\")\n  }\n  return(out)\n}\nmakeIndex<-function(x, inv=FALSE, ret=TRUE, na.rm=TRUE){\n  # Takes an xts object x and returns an index starting at 100 and evolving as the arithmetic returns of x.\n  # The inv flag tells whether or not to invert the series before calculating returns.\n  # The ret flag tells whether or not we have been passed a series of returns already.\n  x<-as.xts(x)\n  init.val<-100\n  nam<-names(x)\n  dts<-as.Date(unlist(strsplit(as.character(index(x)),\" \")))\n  if (na.rm){ \n    data<-apply(x,2,na.omit)\n  }\n  if (inv==TRUE) data<-1/x else data<-x\n  if (ret==TRUE){ # we have a series of returns...\n    ret.series<-data\n  } else {\n    ret.series <- Return.calculate(data, method = \"discrete\")\n  }\n  n<-nrow(ret.series)\n  new.series<-rep(0,n)\n  new.series[1]<-init.val\n  \n  for (i in 2:n){\n    new.series[i]<-(1+ret.series[i])*new.series[i-1]\n  }\n  new.series<-xts(new.series,dts)\n  names(new.series)<-nam\n  return(new.series)\n}\nindexToXTSReturns<-function(x){\n  # takes a data frame of wealth indices and returns an xts object of\n  # returns.\n  \n  if(names(x)[1]==\"Date\"){\n    dts<-as.Date(x$Date,format=\"%Y-%m-%d\")\n    ret<-subset(x,select=-Date)\n    ret<-xts(ret,dts)\n    ret.ret<-apply(ret,MARGIN=2,Return.calculate,method=\"log\")\n  } else {\n    dts<-index(x,0)\n    #we already have an xts object\n    ret.ret<-apply(x,MARGIN=2,Return.calculate,method=\"log\")\n  }\n  ret.ret[1,]<-0\n  ret.ret<-xts(ret.ret,dts)\n  return(ret.ret)\n}\ngetData<-function(tickers, datasrc){\n  # Wrapper for getSymbols that can handle lists of tickers. You can pass a list\n  # of ticker vectors or a single ticker vector.\n  # Recursively calls getData for lists and loads xts objects into .global_env\n  \n  if(class(tickers) %in% \"character\"){\n    for (i in 1:length(tickers)){\n      cat(tickers[i],i,\"\\n\")\n      getSymbols(tickers[i],src=datasrc,\n                 auto.assign=getOption(\"getSymbols.auto.assign\",TRUE),\n                 env=globalenv()) \n    }\n  } else {\n    if(class(tickers) %in% \"list\"){\n      for (i in 1:length(tickers)){\n        getData(tickers[[i]],datasrc) # recursive call to getData\n      }\n    } else {\n      return(\"Invalid parameter type. Should be character vector or list of character vectors.\")\n    }\n  }\n}\ngetManagerData<-function(path){\n  # This function reads in a data series and returns xts variables containing \n  # useful raw data returns, and some indices see below for return data.\n  # Returns a list: the raw data, returns of the managers, a wealth index\n  # created by equally weighted average of the managers, returns from that \n  # composite index.\n  \n  if(is.null(path)) {return(NULL)}\n  mydata = read.csv(path, header=TRUE, sep=\",\")\n  \n  # Clean up the data a bit...\n  comps<-mydata\n  dts<-as.Date(comps$Date,format=\"%Y-%m-%d\") # Grab the date column...\n  comps<-mydata[,2:ncol(mydata)] # no date column...\n  comps<-xts(coredata(comps),dts) # Now our data is in xts format...\n  \n  # Let's check to see whether the user passed return data or wealth index data and do the appropriate thing...\n  if(as.numeric(comps[1,1])==1){\n    # We have wealth index data...\n    comps<-na.locf(comps,na.rm=FALSE) # replace any NA values with the last non-NA value. \n    comps<-comps*100 # Cambridge Associates wealth indices start at 1, not 100.\n    comps.ret<-xts(apply(comps,MARGIN=2,FUN=Return.calculate,method=\"discrete\"),dts)\n    comps.ret[is.na(comps.ret)]<-0 # replace any NA's with zero retuns.\n  } else {\n    # We have return data...\n    comps.ret<-comps\n    comps.ret[is.na(comps.ret)]<-0 # replace any NA's with zero retuns.\n  }\n  \n  # Make an index from the peers frame...\n  comps.index.ret<-as.xts(apply(comps.ret,MARGIN=1,FUN=mean)) # mean arithmetic returns\n  comps.index<-makeIndex(comps.index.ret,inv=FALSE,ret=TRUE)\n  \n  # Now create the list that holds all the variables and return...\n  return(list(\n    mydata=mydata, # the imported data\n    comps.ret=comps.ret, # log return data\n    comps.index=comps.index, # an equally weighted index of the return data\n    comps.index.ret=comps.index.ret # return series for the equally weighted index\n  ))\n}\ntickersToXTS <- function(tickers, na.omit=TRUE){\n  # take a character list of tickers and return an xts object\n  # of the variables. Useful for creating objects after a call to getData().\n  \n  list.variables <- lapply(tickers,get) # a list of actual variables\n  lst.len <- length(list.variables)\n  out <- as.zoo(list.variables[[1]])\n  if(lst.len==1){ # the single element list case...\n    ifelse(na.omit,out <- na.omit(out))\n    return(as.xts(out))\n  } else { # list of length > 1\n    for(i in 2:length(list.variables)){\n      i <- list.variables[[i]]\n      out <- merge.zoo(out,as.zoo(i))\n    }\n    ifelse(na.omit,out <- na.omit(out))\n    return(as.xts(out))\n  }\n}\nplotCovEllipse <- function(a,b){\n  # This function makes a scatterplot of a and b.\n  # It plots the sample histogram in the margins\n  # It overlays the kernal density for a and b. \n  # It overlays the covariance ellipse for a and b\n  ## calculating ellipses\n  \n  a <- as.numeric(coredata(a))\n  b <- as.numeric(coredata(b))\n  \n  if (!(length(a)==length(b))){\n    return(\"Variables are not of conformable length.\")\n  } else {\n    # Calculate some eigen vector/value stuff first.\n    \n    m <- matrix(cov(a,b),2,2)\n    diag(m) <- c(var(a),var(b))\n    ev <- eigen(m)\n    eval <- sqrt(ev$values)\n    evec <- ev$vectors\n    \n    ## Make the ellipsoid from scrath...\n    u <- eval[1]\n    v <- eval[2]\n    x0 <- mean(a)\n    y0 <- mean(b)\n    alpha <- atan(evec[ , 1][2] / evec[ , 1][1]) #arctan of ratio of eigenvectors\n    theta <- seq(0, 2 * pi, length=(1000))\n    \n    x <- x0 + u * cos(theta) * cos(alpha) - v * sin(theta) * sin(alpha)\n    y <- y0 + u * cos(theta) * sin(alpha) + v * sin(theta) * cos(alpha)\n    el <- data.frame(cbind(x,y))\n    \n    #df_ell <- ellipse(m, scale=c(sd(a),sd(b)), centre=c(mean(a),mean(b)))\n    \n    xend1 <- max(el$x)  #eval[1] * evec[ , 1][1]*scalar.a # arrows in covariance ellipspiod...\n    yend1 <- el[which.max(el[,1]),2] #eval[1] * evec[ , 1][2]*scalar.a\n    xend2 <- el[which.min(el[,2]),1] #eval[2] * evec[ , 2][1]\n    yend2 <-  min(el$y) #eval[2] * evec[ , 2][2]*scalar.b\n    angle <- getAngle(c(xend1,yend1),c(xend2,yend2))\n    \n    df <- data.frame(x=a, y=b)\n    \n    hist_top <- ggplot()+geom_histogram(aes(a),colour=\"grey60\",binwidth=.1)+\n      ggtitle(\"Invariant Analysis for Two Assets\")\n    empty <- ggplot()+geom_smooth(aes(a,b), colour=\"red\")+\n      theme(legend.position = \"none\")          \n    \n    hist_right <- ggplot()+geom_histogram(aes(b),colour=\"grey60\",binwidth=.1)+ coord_flip()\n    \n    scatter <- ggplot(data=df, aes(x=x, y=y),colour=\"red\",environment = environment())+\n      geom_point(size=1.5, alpha=.8) +\n      geom_path(data=el, aes(x=x, y=y),colour=\"pink\", size=1.3, linetype=1)+\n      geom_point(aes(x=mean(x),y=mean(y)),colour=\"red\",size=3.5)+ #highlight the location of ellipsoid\n      geom_segment(aes(x = mean(x), y = mean(y), xend = xend1, yend = yend1),colour=\"red\", arrow = arrow(length = unit(0.3, \"cm\")))+\n      geom_segment(aes(x = mean(x), y = mean(y), xend = xend2, yend = yend2),colour=\"blue\", arrow = arrow(length = unit(0.3, \"cm\")))+\n      ggtitle(paste(\"Angle: \",round(angle,3)))\n    \n    #drawing\n    grid.arrange(hist_top, empty, scatter, hist_right, ncol=2, nrow=2, widths=c(3, 1), heights=c(1, 3))\n  }\n}\nplotFitSummary <- function(y, yhat, leverage.factor = 1.0, net.return = NULL,...){\n  # Takes a set of actual values, y, and a set of predicted values, yhat, and produces\n  # a summary plot of the fit. Useful after running any fitting routine where actual\n  # and fitted values are meaningful. Not tested on categorical responses.\n  \n  # Some panel functions that drive the plot...\n  monthly.return.panel <- function(...){\n    #     mtext(c(\"Actual and Predicted Returns\"), side=1, adj=1, line=-3,cex=.8)\n    default.panel(...)\n    #     abline(h=pretty(c(par(\"yaxp\")[1],par(\"yaxp\")[2]),n=par(\"yaxp\")[3]),col=\"gray60\",lty=3)\n    abline(h=0, col=\"grey30\")\n  }\n  \n  cum.return.panel <- function(...){\n    #     mtext(\"Cumualtive Returns\", side=1, adj=1, line=-3,cex=.8)\n    default.panel(...)\n    #     abline(h=pretty(c(par(\"yaxp\")[1],par(\"yaxp\")[2]),n=par(\"yaxp\")[3]),col=\"gray60\",lty=3)\n    abline(h=100, col=\"grey30\")\n  }\n  \n  diff.panel <- function(x,y,...){ #type=\"h\",lwd=5\n    plus.minus.colors <- ifelse(y < 0, \"red\",\"green4\")\n    lines(x, y, type=\"h\", col=plus.minus.colors, lwd = 5, pch = 0)\n    #     mtext(\"Actual - Predicted Monthly Returns\", side=1, adj=1, line=-3,cex=.8)\n    #     default.panel(x,y,...,type=\"h\",lwd=5)\n    #     abline(h=pretty(c(par(\"yaxp\")[1],par(\"yaxp\")[2]),n=par(\"yaxp\")[3]),col=\"gray60\",lty=3)\n    abline(h=0 , col=\"black\") #par(\"usr\")[3]\n  }\n  \n  # Set up the data for plotting...\n  if(!is.null(net.return)){\n    nr.start.date <- paste(first(index(y)),\"/\",sep = \"\")\n    nr.index <- makeIndex(net.return[nr.start.date])\n    plotData <- merge.xts(y, yhat,(y - yhat), makeIndex(y), makeIndex(yhat), \n                          nr.index, makeIndex(leverage.factor*yhat))\n    names(plotData) <- c(\"Actual\", # screen = 1\n                         \"Predicted\", # screen = 1\n                         \"Monthly Difference (bps)\", # screen = 2\n                         \"Cumulative Actual (Gross)\", #screen = 3\n                         \"Cumulative Predicted\", # screen = 3\n                         \"Cumulative Actual (Net)\", # screen = 3 \n                         \"Cumulative Predicted (Risk Matched)\") # screen = 3 \n  } else {\n    plotData <- merge.xts(y, yhat,(y - yhat), makeIndex(y), makeIndex(yhat), \n                          makeIndex(leverage.factor*yhat))\n    names(plotData) <- c(\"Actual\", # screen = 1\n                         \"Predicted\", # screen = 1\n                         \"Monthly Difference (bps)\", # screen = 2\n                         \"Cumulative Actual (Gross)\", #screen = 3\n                         \"Cumulative Predicted\", # screen = 3\n                         \"Cumulative Predicted (Risk Matched)\") # screen = 3 \n  }\n  \n  ## Make the plot...\n  plot.xts(plotData,\n           screens=c(1,1,2,3,3,3,3),\n           layout.screens = matrix(c(1,1,2,3,3,3,3),2,2,byrow=T),\n           lwd = c(2,2,1,2,2,2,2),\n           las=1,\n           lty = c(1,1,1,1,1,1,1),\n           col = c(\"grey60\",\"red\",caGreens[2],caGreens[4],msDarkRed,caBlues[4]),\n           yax.loc = \"left\",\n           ylab = NA,\n           minor.ticks = F,\n           auto.legend = T,\n           legend.pars = list(bty = \"n\", horiz=F), # make legend box transparent. thanks klr.\n           panel=c(monthly.return.panel,diff.panel,cum.return.panel),\n           main  = NA,\n           bty = \"n\"\n  )\n  title(main = \"Performance Summary of Factor Model - Out-of-Sample\", outer = T,\n        line = -1.5, mgp = c(4,1,0))\n}\ngetAngle <- function(u, v){\n  # given two vectors u an v, return the angle between them.\n  \n  numerator <- u[1]*v[1]+u[2]*v[2]\n  denominator <- sqrt(u[1]^2+u[2]^2)*sqrt(v[1]^2+v[2]^2)\n  \n  out <- (acos(numerator/denominator))/0.0174532925\n  return(out)\n}\nvolAdjust <- function(a, target.vol = 1){\n  # takes an xts object x and scales it by target.vol\n  if(ncol(a)==1){\n    vol.scale.factor <- target.vol/sd(a)\n    out <- a*vol.scale.factor\n  } else {\n    vol.scale.factors=xtsApply(a, function(x) target.vol/sd(x))\n    out<-a*vol.scale.factors\n  }\n  return(out)\n}\nrepRow<-function(x, n){\n  matrix(rep(x,each=n),nrow=n)\n}\nrepCol<-function(x, n){\n  matrix(rep(x,each=n), ncol=n, byrow=TRUE)\n}\nsimpSignal<-function(data, lookback = 12){\n  ## This function takes a vector of price signals and returns a vector of momentum signals based on the\n  ## supplied lookback width. lookback default is 12 months. data is assumed to be monthly.\n  f <- periodicity(data)$scale\n  if (f!=\"monthly\"){\n    return(\"This function only accomodates monthly data at present.\")\n  } else {\n    d<-na.omit(data)\n    far.prices<-lag(d,lookback)\n    near.prices<-lag(d,1)\n    signals <- sign(near.prices-far.prices)\n    return(signals)\n  }\n}\nwtdAvgVol <- function(w, R, equal.wt = TRUE, scale = 1){\n  # Given a weight vector and an xts object of returns, this will return\n  # the weighted average volatility assuming all the assets are perfectly uncorrelated.\n  # (ie. all pairwise covariances are zero)\n  # If equal.wt=TRUE, then w is ignored. Otherwise, w is used for the weight vector.\n  \n  if (equal.wt==TRUE){\n    w <- rep(1/ncol(R),ncol(R))\n  }\n  avg.vol <- apply(R,2,sd)*sqrt(scale)\n  wtd.avg.vol  <- t(w)%*%avg.vol\n  \n  return(wtd.avg.vol)\n}\nportfolioVol <- function(w, R, sigma, equal.wt = T, scale = 252){\n  # Compute the portfolio vol from returns, weights, and the covariance matrix\n  # supplied by the user.\n  \n  if(equal.wt==T){\n    w <- rep(1/ncol(R),ncol(R))\n  }\n  S <- sigma\n  out <- sqrt(t(w)%*% S %*% w)*sqrt(scale)\n  return(out)\n}\ndivRatio <- function(w, R, sigma, equal.wt = TRUE, scale=12){\n  # computes the Diversification Ratio from weights, returns, and a covariance matrix.\n  \n  wav <- wtdAvgVol(w=w,R=R,equal.wt=equal.wt,scale=scale)\n  pvol <- portfolioVol(w = w,R = R, sigma = sigma, equal.wt = equal.wt, scale = scale)\n  dr <- wav/pvol\n  colnames(dr) <- \"Diversification Ratio\"\n  return(dr)\n}\nscrubNames <- function(x){\n  # takes an xts object containing fund names and replaces the naems with Fund.x \n  # where x is 1 to ncol(x)\n  \n  out <- x\n  names.scrubbed <- paste(\"Fund.\",seq(1,ncol(x),1),sep=\"\")\n  colnames(out) <- names.scrubbed\n  return(out)\n}\nmakeGrossReturns <- function(nr, mgmt.fee = .02, perf.fee = .20, highwater = TRUE, \n                             ann.exp = .0025, scale = 12){\n  # This function takes a net return stream (nr) and approximates a gross return stream\n  # given the supplied parameters. nr should be in xts format.\n  \n  if(!is.xts(nr)) stop(\"Must supply function with xts object\")\n  dts <- index(nr)\n  nr.index <- makeIndex(nr)\n  gr <- NULL\n  gr[1] <- nr[1]+(mgmt.fee+ann.exp)/scale\n  \n  for (i in 2:nrow(nr)){\n    ## Step 1: gross up nr by the de-annualized fixed expenses\n    gr[i] <- nr[i]+(mgmt.fee+ann.exp)/scale\n    \n    ## Now, we need to check to see if we are above or below the high water mark...\n    hwm <- max(nr.index[0:(i-1)])\n    above.hwm <- ifelse(hwm < nr.index[i],TRUE,FALSE)\n    \n    if (above.hwm){\n      ## manager earns performance fee, so we need to gross up the net return...\n      gr[i] = gr[i]*(1+perf.fee)\n    } \n  }\n  gr <- xts(gr,dts)\n  names(gr) <- \"Gross Return\"\n  return(gr)\n}\npredictionError <- function(y,yhat){\n  # Given two series, the actual values y and the predicted values yhat, returns\n  # the prediction error given by sqrt((mean(y-yhat))^2)\n  \n  ydiff <- y - yhat\n  \n  if(ncol(y) > 0) {\n    # use vecorized functions to handle columns...\n    pe <- apply(ydiff,2,function(x) sqrt(mean((x)^2)))\n  } else {\n    # we have a single column vector...\n    pe <- sqrt(mean((y - yhat)^2))\n  }\n  names(pe) <- names(y)\n  return(pe)\n}\nhitRatio <- function(x, y = NULL){\n  # Given a single track record (x), will return the percentage of \n  # observations greater than or equal to zero.\n  # Given two track records (x and y), will compute the difference (x-y)and \n  # return the percentage of time the difference was positive.\n  \n  if(is.null(y)){\n    # only one track record supplied...\n    out <- sum(as.numeric(x > 0))/length(x)\n  } else {\n    # two track records supplied...\n    if(length(x) != length(y)){\n      return(\"x and y lengths differ. Recycling not appropriate.\")\n    } else {\n      diff.xy <- x - y\n      out <- sum(as.numeric(diff.xy > 0))/length(diff.xy)\n    }\n  }\n  return(out)\n}\ntuneCorrelationCap <- function(train.data, test.data, cor.start = .3, cor.incr = .01){\n  \n  # This function tunes the correlation cap on the factors by examining\n  # the minimum prediction error of the resltant models. \n  # This attempts to optimize the tradeoff of being able to model the asset\n  # more effectively and having large collinearity issues in the coefficients.\n  # Requires caret annd fitTsfm.\n  \n  # Parameters to be passed to fitTsfm. \n  mkt.name <- NULL\n  rf.name <- NULL # we are already supplying excess returns, so we don't need this. Will generate a warning.\n  fit.method <- \"OLS\"\n  variable.selection = \"subsets\"\n  mkt.timing <- NULL\n  really.big <- F # Set to true if # factors greater than 50...\n  \n  factors <- train.data[,2:ncol(train.data)]\n  asset <- train.data[,1]\n  asset.names <- names(asset)\n  cor.factors <- cor(factors)\n  out.err <- NULL\n  data <- NULL\n  \n  nsteps <- (1-cor.start)/cor.incr\n  cat(nsteps,\"\\n\")\n  for (i in 0:nsteps){\n    high.cor.factors <- findCorrelation(cor.factors, cutoff = (cor.start + cor.incr*i))\n    reduced.factors <- factors[,-high.cor.factors]\n    \n    if (ncol(reduced.factors) == 0){\n      out.err[i] <- NA\n    } else {\n      factor.names <- colnames(reduced.factors)\n      data <- merge.xts(assets, reduced.factors, join = \"inner\")\n      \n      fit <- fitTsfm(asset.names = asset.names, \n                     factor.names =  factor.names,\n                     rf.name = rf.name,\n                     data = data,\n                     fit.method=fit.method,\n                     variable.selection=variable.selection,\n                     mkt.timing=mkt.timing,\n                     really.big=really.big)\n      \n      predicted.vals  <- predict(fit, newdata=test.data)\n      actual.vals.test <- test.data[,1:length(predicted.vals)]\n      pred.v <- xts(matrix(unlist(predicted.vals),ncol=length(predicted.vals),byrow=F),index(na.omit(actual.vals.test)))\n      \n      colnames(pred.v) <- asset.names\n      out.err[i] <- c(predictionError(actual.vals.test, pred.v))\n      cat(paste(i,\" \", cor.start + cor.incr*i,\" \", out.err[i]),\"\\n\")\n    }\n  }\n  return (out.err)\n}\n",
    "created" : 1428531694279.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "13|76|25|0|\n26|48|42|0|\n43|34|66|0|\n17|56|19|4|\n67|51|76|0|\n77|48|85|0|\n86|56|113|0|\n114|31|131|0|\n132|36|153|0|\n154|31|194|0|\n195|48|213|0|\n214|32|275|0|\n276|82|348|0|\n6|40|11|2|\n13|36|18|2|\n20|34|27|2|\n349|27|357|0|\n358|41|368|0|\n369|23|371|0|\n372|23|374|0|\n375|42|388|0|\n389|56|402|0|\n403|65|413|0|\n414|61|422|0|\n423|26|431|0|\n433|58|459|0|\n460|36|475|0|\n476|34|495|0|\n496|86|550|0|\n",
    "hash" : "895146604",
    "id" : "775B981D",
    "lastKnownWriteTime" : 1428522488,
    "path" : "~/dMisc_source.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_source"
}